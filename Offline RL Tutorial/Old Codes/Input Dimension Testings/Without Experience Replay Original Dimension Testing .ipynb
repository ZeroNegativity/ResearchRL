{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c118f014",
   "metadata": {},
   "source": [
    "# Original 64 Player Pitt Goal Wall  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "376da4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "def randPair(s,e):\n",
    "    return np.random.randint(s,e), np.random.randint(s,e)\n",
    "\n",
    "class BoardPiece:\n",
    "\n",
    "    def __init__(self, name, code, pos):\n",
    "        self.name = name #name of the piece\n",
    "        self.code = code #an ASCII character to display on the board\n",
    "        self.pos = pos #2-tuple e.g. (1,4)\n",
    "\n",
    "class BoardMask:\n",
    "\n",
    "    def __init__(self, name, mask, code):\n",
    "        self.name = name\n",
    "        self.mask = mask\n",
    "        self.code = code\n",
    "\n",
    "    def get_positions(self): #returns tuple of arrays\n",
    "        return np.nonzero(self.mask)\n",
    "\n",
    "def zip_positions2d(positions): #positions is tuple of two arrays\n",
    "    x,y = positions\n",
    "    return list(zip(x,y))\n",
    "\n",
    "class GridBoard:\n",
    "\n",
    "    def __init__(self, size=4):\n",
    "        self.size = size #Board dimensions, e.g. 4 x 4\n",
    "        self.components = {} #name : board piece\n",
    "        self.masks = {}\n",
    "\n",
    "    def addPiece(self, name, code, pos=(0,0)):\n",
    "        newPiece = BoardPiece(name, code, pos)\n",
    "        self.components[name] = newPiece\n",
    "\n",
    "    #basically a set of boundary elements\n",
    "    def addMask(self, name, mask, code):\n",
    "        #mask is a 2D-numpy array with 1s where the boundary elements are\n",
    "        newMask = BoardMask(name, mask, code)\n",
    "        self.masks[name] = newMask\n",
    "\n",
    "    def movePiece(self, name, pos):\n",
    "        move = True\n",
    "        for _, mask in self.masks.items():\n",
    "            if pos in zip_positions2d(mask.get_positions()):\n",
    "                move = False\n",
    "        if move:\n",
    "            self.components[name].pos = pos\n",
    "\n",
    "    def delPiece(self, name):\n",
    "        del self.components['name']\n",
    "\n",
    "    def render(self):\n",
    "        dtype = '<U2'\n",
    "        displ_board = np.zeros((self.size, self.size), dtype=dtype)\n",
    "        displ_board[:] = ' '\n",
    "\n",
    "        for name, piece in self.components.items():\n",
    "            displ_board[piece.pos] = piece.code\n",
    "\n",
    "        for name, mask in self.masks.items():\n",
    "            displ_board[mask.get_positions()] = mask.code\n",
    "\n",
    "        return displ_board\n",
    "\n",
    "    def render_np(self):\n",
    "        num_pieces = len(self.components) + len(self.masks)\n",
    "        displ_board = np.zeros((num_pieces, self.size, self.size), dtype=np.uint8)\n",
    "        layer = 0\n",
    "        for name, piece in self.components.items():\n",
    "            pos = (layer,) + piece.pos\n",
    "            displ_board[pos] = 1\n",
    "            layer += 1\n",
    "\n",
    "        for name, mask in self.masks.items():\n",
    "            x,y = self.masks['boundary'].get_positions()\n",
    "            z = np.repeat(layer,len(x))\n",
    "            a = (z,x,y)\n",
    "            displ_board[a] = 1\n",
    "            layer += 1\n",
    "        return displ_board\n",
    "\n",
    "def addTuple(a,b):\n",
    "    return tuple([sum(x) for x in zip(a,b)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "967bc8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gridworld:\n",
    "\n",
    "    def __init__(self, size=4, mode='static'):\n",
    "        if size >= 4:\n",
    "            self.board = GridBoard(size=size)\n",
    "        else:\n",
    "            print(\"Minimum board size is 4. Initialized to size 4.\")\n",
    "            self.board = GridBoard(size=4)\n",
    "\n",
    "        #Add pieces, positions will be updated later\n",
    "        self.board.addPiece('Player','P',(0,0))\n",
    "        self.board.addPiece('Goal','+',(1,0))\n",
    "        self.board.addPiece('Pit','-',(2,0))\n",
    "        self.board.addPiece('Wall','W',(3,0))\n",
    "\n",
    "        if mode == 'static':\n",
    "            self.initGridStatic()\n",
    "        elif mode == 'player':\n",
    "            self.initGridPlayer()\n",
    "        else:\n",
    "            self.initGridRand()\n",
    "\n",
    "    #Initialize stationary grid, all items are placed deterministically\n",
    "    def initGridStatic(self):\n",
    "        #Setup static pieces\n",
    "        self.board.components['Player'].pos = (0,3) #Row, Column\n",
    "        self.board.components['Goal'].pos = (0,0)\n",
    "        self.board.components['Pit'].pos = (0,1)\n",
    "        self.board.components['Wall'].pos = (1,1)\n",
    "\n",
    "    #Check if board is initialized appropriately (no overlapping pieces)\n",
    "    #also remove impossible-to-win boards\n",
    "    def validateBoard(self):\n",
    "        valid = True\n",
    "\n",
    "        player = self.board.components['Player']\n",
    "        goal = self.board.components['Goal']\n",
    "        wall = self.board.components['Wall']\n",
    "        pit = self.board.components['Pit']\n",
    "\n",
    "        all_positions = [piece for name,piece in self.board.components.items()]\n",
    "        all_positions = [player.pos, goal.pos, wall.pos, pit.pos]\n",
    "        if len(all_positions) > len(set(all_positions)):\n",
    "            return False\n",
    "\n",
    "        corners = [(0,0),(0,self.board.size), (self.board.size,0), (self.board.size,self.board.size)]\n",
    "        #if player is in corner, can it move? if goal is in corner, is it blocked?\n",
    "        if player.pos in corners or goal.pos in corners:\n",
    "            val_move_pl = [self.validateMove('Player', addpos) for addpos in [(0,1),(1,0),(-1,0),(0,-1)]]\n",
    "            val_move_go = [self.validateMove('Goal', addpos) for addpos in [(0,1),(1,0),(-1,0),(0,-1)]]\n",
    "            if 0 not in val_move_pl or 0 not in val_move_go:\n",
    "                #print(self.display())\n",
    "                #print(\"Invalid board. Re-initializing...\")\n",
    "                valid = False\n",
    "\n",
    "        return valid\n",
    "\n",
    "    #Initialize player in random location, but keep wall, goal and pit stationary\n",
    "    def initGridPlayer(self):\n",
    "        #height x width x depth (number of pieces)\n",
    "        self.initGridStatic()\n",
    "        #place player\n",
    "        self.board.components['Player'].pos = randPair(0,self.board.size)\n",
    "\n",
    "        if (not self.validateBoard()):\n",
    "            #print('Invalid grid. Rebuilding..')\n",
    "            self.initGridPlayer()\n",
    "\n",
    "    #Initialize grid so that goal, pit, wall, player are all randomly placed\n",
    "    def initGridRand(self):\n",
    "        #height x width x depth (number of pieces)\n",
    "        self.board.components['Player'].pos = randPair(0,self.board.size)\n",
    "        self.board.components['Goal'].pos = randPair(0,self.board.size)\n",
    "        self.board.components['Pit'].pos = randPair(0,self.board.size)\n",
    "        self.board.components['Wall'].pos = randPair(0,self.board.size)\n",
    "\n",
    "        if (not self.validateBoard()):\n",
    "            #print('Invalid grid. Rebuilding..')\n",
    "            self.initGridRand()\n",
    "\n",
    "    def validateMove(self, piece, addpos=(0,0)):\n",
    "        outcome = 0 #0 is valid, 1 invalid, 2 lost game\n",
    "        pit = self.board.components['Pit'].pos\n",
    "        wall = self.board.components['Wall'].pos\n",
    "        new_pos = addTuple(self.board.components[piece].pos, addpos)\n",
    "        if new_pos == wall:\n",
    "            outcome = 1 #block move, player can't move to wall\n",
    "        elif max(new_pos) > (self.board.size-1):    #if outside bounds of board\n",
    "            outcome = 1\n",
    "        elif min(new_pos) < 0: #if outside bounds\n",
    "            outcome = 1\n",
    "        elif new_pos == pit:\n",
    "            outcome = 2\n",
    "\n",
    "        return outcome\n",
    "\n",
    "    def makeMove(self, action):\n",
    "        #need to determine what object (if any) is in the new grid spot the player is moving to\n",
    "        #actions in {u,d,l,r}\n",
    "        def checkMove(addpos):\n",
    "            if self.validateMove('Player', addpos) in [0,2]:\n",
    "                new_pos = addTuple(self.board.components['Player'].pos, addpos)\n",
    "                self.board.movePiece('Player', new_pos)\n",
    "\n",
    "        if action == 'u': #up\n",
    "            checkMove((-1,0))\n",
    "        elif action == 'd': #down\n",
    "            checkMove((1,0))\n",
    "        elif action == 'l': #left\n",
    "            checkMove((0,-1))\n",
    "        elif action == 'r': #right\n",
    "            checkMove((0,1))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def reward(self):\n",
    "        if (self.board.components['Player'].pos == self.board.components['Pit'].pos):\n",
    "            return -10\n",
    "        elif (self.board.components['Player'].pos == self.board.components['Goal'].pos):\n",
    "            return 10\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    def display(self):\n",
    "        return self.board.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bca1c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_set = {\n",
    "    0: 'u',\n",
    "    1: 'd',\n",
    "    2: 'l',\n",
    "    3: 'r',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8f77f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, mode='static', display=True):\n",
    "    i = 0\n",
    "    test_game = Gridworld(mode=mode)\n",
    "    state_ = test_game.board.render_np().reshape(1,64) + np.random.rand(1,64)/10.0\n",
    "    state = torch.from_numpy(state_).float()\n",
    "    if display:\n",
    "        print(\"Initial State:\")\n",
    "        print(test_game.display())\n",
    "    status = 1\n",
    "    while(status == 1): #A\n",
    "        qval = model(state)\n",
    "        qval_ = qval.data.numpy()\n",
    "        action_ = np.argmax(qval_) #B\n",
    "        action = action_set[action_]\n",
    "        if display:\n",
    "            print('Move #: %s; Taking action: %s' % (i, action))\n",
    "        test_game.makeMove(action)\n",
    "        state_ = test_game.board.render_np().reshape(1,64) + np.random.rand(1,64)/10.0\n",
    "        state = torch.from_numpy(state_).float()\n",
    "        if display:\n",
    "            print(test_game.display())\n",
    "        reward = test_game.reward()\n",
    "        if reward != -1:\n",
    "            if reward > 0:\n",
    "                status = 2\n",
    "                if display:\n",
    "                    print(\"Game won! Reward: %s\" % (reward,))\n",
    "            else:\n",
    "                status = 0\n",
    "                if display:\n",
    "                    print(\"Game LOST. Reward: %s\" % (reward,))\n",
    "        i += 1\n",
    "        if (i > 15):\n",
    "            if display:\n",
    "                print(\"Game lost; too many moves.\")\n",
    "            break\n",
    "    \n",
    "    win = True if status == 2 else False\n",
    "    return win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c28dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "l1 = 64\n",
    "l2 = 150\n",
    "l3 = 100\n",
    "l4 = 4\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(l1, l2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(l2, l3),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(l3,l4)\n",
    ")\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "gamma = 0.9\n",
    "epsilon = 1.0\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "gamma = 0.9\n",
    "epsilon = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8de80ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999 148.4224853515625\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "losses = [] #A\n",
    "for i in range(epochs): #B\n",
    "    game = Gridworld(size=4, mode='random') #C\n",
    "    state_ = game.board.render_np().reshape(1,64) + np.random.rand(1,64)/10.0 #D\n",
    "    state1 = torch.from_numpy(state_).float() #E\n",
    "    status = 1 #F\n",
    "    while(status == 1): #G\n",
    "        qval = model(state1) #H\n",
    "        qval_ = qval.data.numpy()\n",
    "        if (random.random() < epsilon): #I\n",
    "            action_ = np.random.randint(0,4)\n",
    "        else:\n",
    "            action_ = np.argmax(qval_)\n",
    "        \n",
    "        action = action_set[action_] #J\n",
    "        game.makeMove(action) #K\n",
    "        state2_ = game.board.render_np().reshape(1,64) + np.random.rand(1,64)/10.0\n",
    "        state2 = torch.from_numpy(state2_).float() #L\n",
    "        reward = game.reward()\n",
    "        with torch.no_grad():\n",
    "            newQ = model(state2.reshape(1,64))\n",
    "        maxQ = torch.max(newQ) #M\n",
    "        if reward == -1: #N\n",
    "            Y = reward + (gamma * maxQ)\n",
    "        else:\n",
    "            Y = reward\n",
    "        Y = torch.Tensor([Y]).detach()\n",
    "        X = qval.squeeze()[action_] #O\n",
    "        loss = loss_fn(X, Y) #P\n",
    "        print(i, loss.item())\n",
    "        clear_output(wait=True)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        state1 = state2\n",
    "        if reward != -1: #Q\n",
    "            status = 0\n",
    "    if epsilon > 0.1: #R\n",
    "        epsilon -= (1/epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78335a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games played: 1000, # of wins: 483\n",
      "0.483\n",
      "0.483\n",
      "Games played: 1000, # of wins: 478\n",
      "0.478\n",
      "0.961\n",
      "Games played: 1000, # of wins: 481\n",
      "0.481\n",
      "1.442\n",
      "Games played: 1000, # of wins: 464\n",
      "0.464\n",
      "1.906\n",
      "Games played: 1000, # of wins: 466\n",
      "0.466\n",
      "2.372\n",
      "Games played: 1000, # of wins: 475\n",
      "0.475\n",
      "2.847\n",
      "Games played: 1000, # of wins: 469\n",
      "0.469\n",
      "3.316\n",
      "Games played: 1000, # of wins: 463\n",
      "0.463\n",
      "3.779\n",
      "Games played: 1000, # of wins: 505\n",
      "0.505\n",
      "4.284\n",
      "Games played: 1000, # of wins: 491\n",
      "0.491\n",
      "4.7749999999999995\n",
      "Win percentage: 47.74999999999999%\n"
     ]
    }
   ],
   "source": [
    "win_num = 0\n",
    "for i in range(0,10):\n",
    "    max_games = 1000\n",
    "    wins = 0\n",
    "    for i in range(max_games):\n",
    "        win = test_model(model, mode='random', display=False)\n",
    "        if win:\n",
    "            wins += 1\n",
    "    win_perc = float(wins) / float(max_games)\n",
    "    win_num = win_num + win_perc\n",
    "    print(\"Games played: {0}, # of wins: {1}\".format(max_games,wins))\n",
    "    print(win_perc)\n",
    "    print(win_num)\n",
    "win_num = win_num / 10\n",
    "print(\"Win percentage: {}%\".format(win_num*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7c851e",
   "metadata": {},
   "source": [
    "# Pit Player Goal Wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c86e414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "def randPair(s,e):\n",
    "    return np.random.randint(s,e), np.random.randint(s,e)\n",
    "\n",
    "class BoardPiece:\n",
    "\n",
    "    def __init__(self, name, code, pos):\n",
    "        self.name = name #name of the piece\n",
    "        self.code = code #an ASCII character to display on the board\n",
    "        self.pos = pos #2-tuple e.g. (1,4)\n",
    "\n",
    "class BoardMask:\n",
    "\n",
    "    def __init__(self, name, mask, code):\n",
    "        self.name = name\n",
    "        self.mask = mask\n",
    "        self.code = code\n",
    "\n",
    "    def get_positions(self): #returns tuple of arrays\n",
    "        return np.nonzero(self.mask)\n",
    "\n",
    "def zip_positions2d(positions): #positions is tuple of two arrays\n",
    "    x,y = positions\n",
    "    return list(zip(x,y))\n",
    "\n",
    "class GridBoard:\n",
    "\n",
    "    def __init__(self, size=4):\n",
    "        self.size = size #Board dimensions, e.g. 4 x 4\n",
    "        self.components = {} #name : board piece\n",
    "        self.masks = {}\n",
    "\n",
    "    def addPiece(self, name, code, pos=(0,0)):\n",
    "        newPiece = BoardPiece(name, code, pos)\n",
    "        self.components[name] = newPiece\n",
    "\n",
    "    #basically a set of boundary elements\n",
    "    def addMask(self, name, mask, code):\n",
    "        #mask is a 2D-numpy array with 1s where the boundary elements are\n",
    "        newMask = BoardMask(name, mask, code)\n",
    "        self.masks[name] = newMask\n",
    "\n",
    "    def movePiece(self, name, pos):\n",
    "        move = True\n",
    "        for _, mask in self.masks.items():\n",
    "            if pos in zip_positions2d(mask.get_positions()):\n",
    "                move = False\n",
    "        if move:\n",
    "            self.components[name].pos = pos\n",
    "\n",
    "    def delPiece(self, name):\n",
    "        del self.components['name']\n",
    "\n",
    "    def render(self):\n",
    "        dtype = '<U2'\n",
    "        displ_board = np.zeros((self.size, self.size), dtype=dtype)\n",
    "        displ_board[:] = ' '\n",
    "\n",
    "        for name, piece in self.components.items():\n",
    "            displ_board[piece.pos] = piece.code\n",
    "\n",
    "        for name, mask in self.masks.items():\n",
    "            displ_board[mask.get_positions()] = mask.code\n",
    "\n",
    "        return displ_board\n",
    "\n",
    "    def render_np(self):\n",
    "        num_pieces = len(self.components) + len(self.masks)\n",
    "        displ_board = np.zeros((num_pieces, self.size, self.size), dtype=np.uint8)\n",
    "        layer = 0\n",
    "        pos = []\n",
    "        for name, piece in self.components.items():\n",
    "            if name == 'Player':\n",
    "                pos = (1,) + piece.pos\n",
    "                displ_board[pos] = 1\n",
    "                layer += 1\n",
    "            if name == 'Pit':\n",
    "                pos = (0,) + piece.pos\n",
    "                displ_board[pos] = 1\n",
    "                layer += 1\n",
    "            if name == 'Goal':\n",
    "                pos = (2,) + piece.pos\n",
    "                displ_board[pos] = 1\n",
    "                layer += 1\n",
    "            if name == 'Wall':\n",
    "                pos = (3,) + piece.pos\n",
    "                displ_board[pos] = 1\n",
    "                layer += 1\n",
    "        for name, mask in self.masks.items():\n",
    "            x,y = self.masks['boundary'].get_positions()\n",
    "            z = np.repeat(layer,len(x))\n",
    "            a = (z,x,y)\n",
    "            displ_board[a] = 1\n",
    "            layer += 1\n",
    "            print(mask)\n",
    "        print(layer)\n",
    "        return displ_board\n",
    "\n",
    "def addTuple(a,b):\n",
    "    return tuple([sum(x) for x in zip(a,b)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7365c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "l1 = 64\n",
    "l2 = 150\n",
    "l3 = 100\n",
    "l4 = 4\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(l1, l2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(l2, l3),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(l3,l4)\n",
    ")\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "gamma = 0.9\n",
    "epsilon = 1.0\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "gamma = 0.9\n",
    "epsilon = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06d8ba79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "999 141.50167846679688\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "losses = [] #A\n",
    "for i in range(epochs): #B\n",
    "    game = Gridworld(size=4, mode='random') #C\n",
    "    state_ = game.board.render_np().reshape(1,64) + np.random.rand(1,64)/10.0 #D\n",
    "    state1 = torch.from_numpy(state_).float() #E\n",
    "    status = 1 #F\n",
    "    while(status == 1): #G\n",
    "        qval = model(state1) #H\n",
    "        qval_ = qval.data.numpy()\n",
    "        if (random.random() < epsilon): #I\n",
    "            action_ = np.random.randint(0,4)\n",
    "        else:\n",
    "            action_ = np.argmax(qval_)\n",
    "        \n",
    "        action = action_set[action_] #J\n",
    "        game.makeMove(action) #K\n",
    "        state2_ = game.board.render_np().reshape(1,64) + np.random.rand(1,64)/10.0\n",
    "        state2 = torch.from_numpy(state2_).float() #L\n",
    "        reward = game.reward()\n",
    "        with torch.no_grad():\n",
    "            newQ = model(state2.reshape(1,64))\n",
    "        maxQ = torch.max(newQ) #M\n",
    "        if reward == -1: #N\n",
    "            Y = reward + (gamma * maxQ)\n",
    "        else:\n",
    "            Y = reward\n",
    "        Y = torch.Tensor([Y]).detach()\n",
    "        X = qval.squeeze()[action_] #O\n",
    "        loss = loss_fn(X, Y) #P\n",
    "        print(i, loss.item())\n",
    "        clear_output(wait=True)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        state1 = state2\n",
    "        if reward != -1: #Q\n",
    "            status = 0\n",
    "    if epsilon > 0.1: #R\n",
    "        epsilon -= (1/epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c344022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games played: 1000, # of wins: 428\n",
      "0.428\n",
      "0.428\n",
      "Games played: 1000, # of wins: 435\n",
      "0.435\n",
      "0.863\n",
      "Games played: 1000, # of wins: 399\n",
      "0.399\n",
      "1.262\n",
      "Games played: 1000, # of wins: 436\n",
      "0.436\n",
      "1.698\n",
      "Games played: 1000, # of wins: 431\n",
      "0.431\n",
      "2.129\n",
      "Games played: 1000, # of wins: 409\n",
      "0.409\n",
      "2.538\n",
      "Games played: 1000, # of wins: 424\n",
      "0.424\n",
      "2.9619999999999997\n",
      "Games played: 1000, # of wins: 381\n",
      "0.381\n",
      "3.343\n",
      "Games played: 1000, # of wins: 413\n",
      "0.413\n",
      "3.756\n",
      "Games played: 1000, # of wins: 395\n",
      "0.395\n",
      "4.151\n",
      "Win percentage: 41.51%\n"
     ]
    }
   ],
   "source": [
    "win_num = 0\n",
    "for i in range(0,10):\n",
    "    max_games = 1000\n",
    "    wins = 0\n",
    "    for i in range(max_games):\n",
    "        win = test_model(model, mode='random', display=False)\n",
    "        if win:\n",
    "            wins += 1\n",
    "    win_perc = float(wins) / float(max_games)\n",
    "    win_num = win_num + win_perc\n",
    "    print(\"Games played: {0}, # of wins: {1}\".format(max_games,wins))\n",
    "    print(win_perc)\n",
    "    print(win_num)\n",
    "win_num = win_num / 10\n",
    "print(\"Win percentage: {}%\".format(win_num*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1bba5b",
   "metadata": {},
   "source": [
    "# Mask Pit Player Goal Wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90793e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "def randPair(s,e):\n",
    "    return np.random.randint(s,e), np.random.randint(s,e)\n",
    "\n",
    "class BoardPiece:\n",
    "\n",
    "    def __init__(self, name, code, pos):\n",
    "        self.name = name #name of the piece\n",
    "        self.code = code #an ASCII character to display on the board\n",
    "        self.pos = pos #2-tuple e.g. (1,4)\n",
    "\n",
    "class BoardMask:\n",
    "\n",
    "    def __init__(self, name, mask, code):\n",
    "        self.name = name\n",
    "        self.mask = mask\n",
    "        self.code = code\n",
    "\n",
    "    def get_positions(self): #returns tuple of arrays\n",
    "        return np.nonzero(self.mask)\n",
    "\n",
    "def zip_positions2d(positions): #positions is tuple of two arrays\n",
    "    x,y = positions\n",
    "    return list(zip(x,y))\n",
    "\n",
    "class GridBoard:\n",
    "\n",
    "    def __init__(self, size=4):\n",
    "        self.size = size #Board dimensions, e.g. 4 x 4\n",
    "        self.components = {} #name : board piece\n",
    "        self.masks = {}\n",
    "\n",
    "    def addPiece(self, name, code, pos=(0,0)):\n",
    "        newPiece = BoardPiece(name, code, pos)\n",
    "        self.components[name] = newPiece\n",
    "\n",
    "    #basically a set of boundary elements\n",
    "    def addMask(self, name, mask, code):\n",
    "        #mask is a 2D-numpy array with 1s where the boundary elements are\n",
    "        newMask = BoardMask(name, mask, code)\n",
    "        self.masks[name] = newMask\n",
    "\n",
    "    def movePiece(self, name, pos):\n",
    "        move = True\n",
    "        for _, mask in self.masks.items():\n",
    "            if pos in zip_positions2d(mask.get_positions()):\n",
    "                move = False\n",
    "        if move:\n",
    "            self.components[name].pos = pos\n",
    "\n",
    "    def delPiece(self, name):\n",
    "        del self.components['name']\n",
    "\n",
    "    def render(self):\n",
    "        dtype = '<U2'\n",
    "        displ_board = np.zeros((self.size, self.size), dtype=dtype)\n",
    "        displ_board[:] = ' '\n",
    "\n",
    "        for name, piece in self.components.items():\n",
    "            displ_board[piece.pos] = piece.code\n",
    "\n",
    "        for name, mask in self.masks.items():\n",
    "            displ_board[mask.get_positions()] = mask.code\n",
    "\n",
    "        return displ_board\n",
    "\n",
    "    def render_np(self):\n",
    "        num_pieces = len(self.components) + len(self.masks)\n",
    "        displ_board = np.zeros((num_pieces, self.size, self.size), dtype=np.uint8)\n",
    "        layer = 0\n",
    "        pos = []\n",
    "        for name, piece in self.components.items():\n",
    "            if name == 'Player':\n",
    "                pos = (1,) + piece.pos\n",
    "                displ_board[pos] = 1\n",
    "                layer += 1\n",
    "            if name == 'Pit':\n",
    "                pos = (0,) + piece.pos\n",
    "                displ_board[pos] = 1\n",
    "                layer += 1\n",
    "            if name == 'Goal':\n",
    "                pos = (2,) + piece.pos\n",
    "                displ_board[pos] = 1\n",
    "                layer += 1\n",
    "            if name == 'Wall':\n",
    "                pos = (3,) + piece.pos\n",
    "                displ_board[pos] = 1\n",
    "                layer += 1\n",
    "\n",
    "        for name, mask in self.masks.items():\n",
    "            if name == 'Player':\n",
    "                x,y = self.masks['boundary'].get_positions()\n",
    "                z = np.repeat(1,len(x))\n",
    "                a = (z,x,y)\n",
    "                displ_board[a] = 1\n",
    "                print(mask)\n",
    "            if name == 'Pit':\n",
    "                x,y = self.masks['boundary'].get_positions()\n",
    "                z = np.repeat(0,len(x))\n",
    "                a = (z,x,y)\n",
    "                displ_board[a] = 1\n",
    "                print(mask)\n",
    "            if name == 'Goal':\n",
    "                x,y = self.masks['boundary'].get_positions()\n",
    "                z = np.repeat(2,len(x))\n",
    "                a = (z,x,y)\n",
    "                displ_board[a] = 1\n",
    "                print(mask)\n",
    "            if name == 'Wall':\n",
    "                x,y = self.masks['boundary'].get_positions()\n",
    "                z = np.repeat(3,len(x))\n",
    "                a = (z,x,y)\n",
    "                displ_board[a] = 1\n",
    "                print(mask)\n",
    "        return displ_board\n",
    "\n",
    "def addTuple(a,b):\n",
    "    return tuple([sum(x) for x in zip(a,b)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8539d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "l1 = 64\n",
    "l2 = 150\n",
    "l3 = 100\n",
    "l4 = 4\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(l1, l2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(l2, l3),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(l3,l4)\n",
    ")\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "gamma = 0.9\n",
    "epsilon = 1.0\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "gamma = 0.9\n",
    "epsilon = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4fcc7f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999 50.00202178955078\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "losses = [] #A\n",
    "for i in range(epochs): #B\n",
    "    game = Gridworld(size=4, mode='random') #C\n",
    "    state_ = game.board.render_np().reshape(1,64) + np.random.rand(1,64)/10.0 #D\n",
    "    state1 = torch.from_numpy(state_).float() #E\n",
    "    status = 1 #F\n",
    "    while(status == 1): #G\n",
    "        qval = model(state1) #H\n",
    "        qval_ = qval.data.numpy()\n",
    "        if (random.random() < epsilon): #I\n",
    "            action_ = np.random.randint(0,4)\n",
    "        else:\n",
    "            action_ = np.argmax(qval_)\n",
    "        \n",
    "        action = action_set[action_] #J\n",
    "        game.makeMove(action) #K\n",
    "        state2_ = game.board.render_np().reshape(1,64) + np.random.rand(1,64)/10.0\n",
    "        state2 = torch.from_numpy(state2_).float() #L\n",
    "        reward = game.reward()\n",
    "        with torch.no_grad():\n",
    "            newQ = model(state2.reshape(1,64))\n",
    "        maxQ = torch.max(newQ) #M\n",
    "        if reward == -1: #N\n",
    "            Y = reward + (gamma * maxQ)\n",
    "        else:\n",
    "            Y = reward\n",
    "        Y = torch.Tensor([Y]).detach()\n",
    "        X = qval.squeeze()[action_] #O\n",
    "        loss = loss_fn(X, Y) #P\n",
    "        print(i, loss.item())\n",
    "        clear_output(wait=True)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        state1 = state2\n",
    "        if reward != -1: #Q\n",
    "            status = 0\n",
    "    if epsilon > 0.1: #R\n",
    "        epsilon -= (1/epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a51c1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games played: 1000, # of wins: 550\n",
      "0.55\n",
      "0.55\n",
      "Games played: 1000, # of wins: 560\n",
      "0.56\n",
      "1.11\n",
      "Games played: 1000, # of wins: 562\n",
      "0.562\n",
      "1.6720000000000002\n",
      "Games played: 1000, # of wins: 576\n",
      "0.576\n",
      "2.248\n",
      "Games played: 1000, # of wins: 567\n",
      "0.567\n",
      "2.8150000000000004\n",
      "Games played: 1000, # of wins: 560\n",
      "0.56\n",
      "3.3750000000000004\n",
      "Games played: 1000, # of wins: 561\n",
      "0.561\n",
      "3.9360000000000004\n",
      "Games played: 1000, # of wins: 530\n",
      "0.53\n",
      "4.466\n",
      "Games played: 1000, # of wins: 539\n",
      "0.539\n",
      "5.005\n",
      "Games played: 1000, # of wins: 561\n",
      "0.561\n",
      "5.566\n",
      "Win percentage: 55.66%\n"
     ]
    }
   ],
   "source": [
    "win_num = 0\n",
    "for i in range(0,10):\n",
    "    max_games = 1000\n",
    "    wins = 0\n",
    "    for i in range(max_games):\n",
    "        win = test_model(model, mode='random', display=False)\n",
    "        if win:\n",
    "            wins += 1\n",
    "    win_perc = float(wins) / float(max_games)\n",
    "    win_num = win_num + win_perc\n",
    "    print(\"Games played: {0}, # of wins: {1}\".format(max_games,wins))\n",
    "    print(win_perc)\n",
    "    print(win_num)\n",
    "win_num = win_num / 10\n",
    "print(\"Win percentage: {}%\".format(win_num*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498fa3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
